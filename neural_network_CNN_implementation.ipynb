{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_network_CNN_implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahyash07/CNN-implementation-for-digit-classification/blob/master/neural_network_CNN_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0539Pwt1Ygwz",
        "colab_type": "text"
      },
      "source": [
        "# Project objective\n",
        "Digit classification from 70,000 samples dataset using CNN. \n",
        "\n",
        "This peoject is demontsration of Convolutional nural network application \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57oB2idEgr-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import keras \n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "from sklearn import metrics"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb1Zm7ARN5D5",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to the dataset\n",
        "\n",
        "**Summary**: Recognizing hand-written digits  \n",
        "\n",
        "**number of features**: 28 pixels in rows and 28 pixels in columns \n",
        "\n",
        "**Size** : 70,000 samples \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RILQWrhjQUtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMPORTING DATASET\n",
        "\n",
        "#download mnist data and split into train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VeVlmRJdly9",
        "colab_type": "text"
      },
      "source": [
        "## Checking the parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpSupKvgdS3e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "520e59b8-58ce-438a-bbd9-cd3bb2b3cdf5"
      },
      "source": [
        "print('Shapes of the images: {}'.format(X_train.shape))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes of the images: (60000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUxyqRYycT4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIX-LbyLeEc6",
        "colab_type": "text"
      },
      "source": [
        "## Data preparation\n",
        "We need to prepare the dataset for machine learnign modeling.  we prepare the data in 2 steps:\n",
        "\n",
        "- Reshaping input features (pixels of images) to the shape that we can later use in the modeling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GI52MUkePCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reshape data to fit model\n",
        "# Interpretation of the numbers in the reshape function\n",
        "# 1) number of data points (images),  2 and 3) number of pixels in rows and columns  4) 1 stands for greyscale\n",
        "X_train = X_train.reshape(60000,28,28,1)\n",
        "X_test = X_test.reshape(10000,28,28,1)\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uoY9davmhJZS",
        "colab_type": "text"
      },
      "source": [
        "- Converting the integer array of labels to one-hot encodings to be used in neural network modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxuuyOP9t9xY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dbc6b1a2-43d1-49b1-f848-4feed71dc400"
      },
      "source": [
        "\n",
        "#one-hot encode target column\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "print(\"so here 5 converts to the \")\n",
        "print('One hot vector of the first image in the training set: {}'.format(y_train[0]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "so here 5 converts to the \n",
            "One hot vector of the first image in the training set: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAwb3l47hXkL",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0Fi1jpVkbhC",
        "colab_type": "text"
      },
      "source": [
        "## Building the supervised learning model\n",
        "We want to build a multi-class classification model as the output variable include multiple classes. \n",
        "\n",
        "\n",
        "Here we build a neural network model with 2 hidden layers.\n",
        "\n",
        "\n",
        "### Convolutional neural network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj3SSteMkxb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# building a neural network model\n",
        "model = Sequential()\n",
        "\n",
        "# Adding 1st hidden layer with 32 as the number of output filters in the convolution\n",
        "# input_dim should be specified as the number of input features\n",
        "# kernel_size is the size of the convolutional filters. Here we are using 3*3 filteres.\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
        "\n",
        "# Adding 2nd hidden layer with 16 as the number of output filters in the convolution\n",
        "model.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
        "\n",
        "# We want to flatten the image shape matrices of the last hidden layer\n",
        "# and then use the results in the output layer\n",
        "model.add(Flatten())\n",
        "\n",
        "# adding the output layer (softmax is used to generate probabilities for each predicted class)\n",
        "# Size if the last layer should be equal to the total number of classes in the dataset which is 10\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# compiling the model using cross-entropy for categorical variables,\n",
        "# as we are dealing with multi-class classification\n",
        "# Adam optimization algorithm is also used\n",
        "# Accuracy is used as the metric to assess performance of our model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgszolas0q7X",
        "colab_type": "text"
      },
      "source": [
        "Now we fit our neural network model using the training set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od9xWVWhzp28",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "ae948e2c-9a09-4172-cbb6-14b2331024a6"
      },
      "source": [
        "# Train the model using the training set\n",
        "# We can also check the performance of the model after every epoch on the validation set. \n",
        "# Here we use the test set of MNIST dataset to check the performance on the validation set.\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.2318 - accuracy: 0.9472 - val_loss: 0.0910 - val_accuracy: 0.9719\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0772 - accuracy: 0.9769 - val_loss: 0.0851 - val_accuracy: 0.9747\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 80s 42ms/step - loss: 0.0528 - accuracy: 0.9834 - val_loss: 0.0978 - val_accuracy: 0.9750\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0410 - accuracy: 0.9871 - val_loss: 0.1073 - val_accuracy: 0.9760\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0300 - accuracy: 0.9904 - val_loss: 0.1169 - val_accuracy: 0.9747\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0263 - accuracy: 0.9922 - val_loss: 0.1302 - val_accuracy: 0.9768\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 80s 42ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.1367 - val_accuracy: 0.9782\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0258 - accuracy: 0.9933 - val_loss: 0.1577 - val_accuracy: 0.9772\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0186 - accuracy: 0.9950 - val_loss: 0.1880 - val_accuracy: 0.9761\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0188 - accuracy: 0.9954 - val_loss: 0.1706 - val_accuracy: 0.9763\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e4aba8e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB1EfbdcvFVf",
        "colab_type": "text"
      },
      "source": [
        "Accuracy of the model in the validation set is higher than training set after the first epoch. This is not something unusual. The model could perform better in teh validation set after the first few epochs as the number and distribution of datapoints are different between the trainign and validation sets. However, as the model gets better and better, trainign set accuracy goes abovevalidation set accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWb1aK68rGfT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "The concept of **early stopping** - we can stop when the validation loss starts increasing in a consistent way. \n",
        "stopping the model after 4 epochs of training for this model would have been a good choice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G47lNfjGlWd0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "69078527-9a48-409c-ba82-e88e1324d191"
      },
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=4)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.2036 - accuracy: 0.9507 - val_loss: 0.1038 - val_accuracy: 0.9693\n",
            "Epoch 2/4\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0679 - accuracy: 0.9793 - val_loss: 0.0798 - val_accuracy: 0.9757\n",
            "Epoch 3/4\n",
            "1875/1875 [==============================] - 81s 43ms/step - loss: 0.0465 - accuracy: 0.9850 - val_loss: 0.0866 - val_accuracy: 0.9769\n",
            "Epoch 4/4\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 0.0817 - val_accuracy: 0.9739\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3e48461be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS3yoMz7vCWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyBVyd9QqS4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Converting predictions to label\n",
        "pred = list()\n",
        "for i in range(len(y_pred)):\n",
        "    pred.append(np.argmax(y_pred[i]))\n",
        "#Converting one hot encoded test label to label\n",
        "test = list()\n",
        "for i in range(len(y_test)):\n",
        "    test.append(np.argmax(y_test[i]))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-Uby3AV1OID",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating performance of the model\n",
        "We need to assess performance of the model using the predictions of the test set. We use accuracy and balanced accuracy. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdDOtXow1CKT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d45f6983-2b3d-4df0-c7b1-458e1fc48305"
      },
      "source": [
        "\n",
        "\n",
        "print('Accuracy of the neural network model is:', metrics.accuracy_score(pred,test)*100)\n",
        "\n",
        "print(\"Blanced accuracy of the neural network model is:\", metrics.balanced_accuracy_score(pred, test))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the neural network model is: 97.39\n",
            "Blanced accuracy of the neural network model is: 0.9739449415176397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8nqaGoypmnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": []
    }
  ]
}